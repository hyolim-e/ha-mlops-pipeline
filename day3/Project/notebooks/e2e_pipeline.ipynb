{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3-2: E2E ML Pipeline (Part 1)\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **End-to-End ML Pipeline**ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "1. Kubeflow Pipeline êµ¬ì„±ìš”ì†Œ ì´í•´\n",
    "2. MLflow ì—°ë™\n",
    "3. ì¡°ê±´ë¶€ ë°°í¬\n",
    "4. KServe ë°°í¬\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install kfp>=2.0.0 mlflow>=2.9.0 scikit-learn pandas numpy -q\n",
    "print(\"âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import os\n",
    "from kfp import dsl\n",
    "from kfp.dsl import component, Input, Output, Dataset, Model\n",
    "from kfp import compiler\n",
    "import kfp\n",
    "\n",
    "print(f\"KFP Version: {kfp.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
    "USER_NUM = \"01\"  # TODO: ë³¸ì¸ ë²ˆí˜¸ë¡œ ë³€ê²½!\n",
    "USER_NAMESPACE = f\"kubeflow-user{USER_NUM}\"\n",
    "\n",
    "MLFLOW_TRACKING_URI = os.getenv(\n",
    "    'MLFLOW_TRACKING_URI',\n",
    "    'http://mlflow-server-service.mlflow-system.svc.cluster.local:5000'\n",
    ")\n",
    "\n",
    "print(f\"User Number: {USER_NUM}\")\n",
    "print(f\"Namespace: {USER_NAMESPACE}\")\n",
    "print(f\"MLflow URI: {MLFLOW_TRACKING_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. ì»´í¬ë„ŒíŠ¸ ì •ì˜\n",
    "\n",
    "### 2.1 ë°ì´í„° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\"pandas==2.0.3\", \"scikit-learn==1.3.2\"]\n",
    ")\n",
    "def load_data(data_source: str, output_data: Output[Dataset]):\n",
    "    \"\"\"California Housing ë°ì´í„°ì…‹ ë¡œë“œ\"\"\"\n",
    "    import pandas as pd\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"  Step 1: Load Data\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if data_source == \"sklearn\":\n",
    "        housing = fetch_california_housing(as_frame=True)\n",
    "        df = housing.frame\n",
    "    else:\n",
    "        df = pd.read_csv(data_source)\n",
    "    \n",
    "    print(f\"  Data shape: {df.shape}\")\n",
    "    df.to_csv(output_data.path, index=False)\n",
    "    print(f\"  âœ… Saved to: {output_data.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\"pandas==2.0.3\", \"scikit-learn==1.3.2\", \"numpy==1.24.3\"]\n",
    ")\n",
    "def preprocess(\n",
    "    input_data: Input[Dataset],\n",
    "    X_train_out: Output[Dataset],\n",
    "    X_test_out: Output[Dataset],\n",
    "    y_train_out: Output[Dataset],\n",
    "    y_test_out: Output[Dataset],\n",
    "    test_size: float = 0.2\n",
    "):\n",
    "    \"\"\"ë°ì´í„° ì „ì²˜ë¦¬: Train/Test ë¶„í•  ë° ì •ê·œí™”\"\"\"\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"  Step 2: Preprocess\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    df = pd.read_csv(input_data.path)\n",
    "    \n",
    "    X = df.drop(columns=['MedHouseVal'])\n",
    "    y = df['MedHouseVal']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42\n",
    "    )\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(X_train),\n",
    "        columns=X_train.columns\n",
    "    )\n",
    "    X_test_scaled = pd.DataFrame(\n",
    "        scaler.transform(X_test),\n",
    "        columns=X_test.columns\n",
    "    )\n",
    "    \n",
    "    X_train_scaled.to_csv(X_train_out.path, index=False)\n",
    "    X_test_scaled.to_csv(X_test_out.path, index=False)\n",
    "    y_train.to_csv(y_train_out.path, index=False)\n",
    "    y_test.to_csv(y_test_out.path, index=False)\n",
    "    \n",
    "    print(f\"  Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "    print(f\"  âœ… Preprocessing completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\"pandas==2.0.3\", \"numpy==1.24.3\"]\n",
    ")\n",
    "def feature_engineering(\n",
    "    X_train_in: Input[Dataset],\n",
    "    X_test_in: Input[Dataset],\n",
    "    X_train_out: Output[Dataset],\n",
    "    X_test_out: Output[Dataset]\n",
    "):\n",
    "    \"\"\"í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§: íŒŒìƒ ë³€ìˆ˜ ìƒì„±\"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"  Step 3: Feature Engineering\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    X_train = pd.read_csv(X_train_in.path)\n",
    "    X_test = pd.read_csv(X_test_in.path)\n",
    "    \n",
    "    def add_features(df):\n",
    "        df = df.copy()\n",
    "        df['rooms_per_household'] = df['AveRooms'] / (df['AveOccup'] + 1e-6)\n",
    "        df['bedrooms_ratio'] = df['AveBedrms'] / (df['AveRooms'] + 1e-6)\n",
    "        df['population_per_household'] = df['Population'] / (df['AveOccup'] + 1e-6)\n",
    "        return df\n",
    "    \n",
    "    X_train_fe = add_features(X_train)\n",
    "    X_test_fe = add_features(X_test)\n",
    "    \n",
    "    X_train_fe.to_csv(X_train_out.path, index=False)\n",
    "    X_test_fe.to_csv(X_test_out.path, index=False)\n",
    "    \n",
    "    print(f\"  Features: {len(X_train_fe.columns)}\")\n",
    "    print(f\"  âœ… Feature engineering completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 ëª¨ë¸ í•™ìŠµ (MLflow ì—°ë™)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\n",
    "        \"pandas==2.0.3\",\n",
    "        \"scikit-learn==1.3.2\",\n",
    "        \"mlflow==2.9.2\",\n",
    "        \"numpy==1.24.3\"\n",
    "    ]\n",
    ")\n",
    "def train_model(\n",
    "    X_train: Input[Dataset],\n",
    "    X_test: Input[Dataset],\n",
    "    y_train: Input[Dataset],\n",
    "    y_test: Input[Dataset],\n",
    "    mlflow_tracking_uri: str,\n",
    "    experiment_name: str,\n",
    "    n_estimators: int = 100,\n",
    "    max_depth: int = 10\n",
    ") -> str:\n",
    "    \"\"\"ëª¨ë¸ í•™ìŠµ ë° MLflow ê¸°ë¡\"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import mlflow\n",
    "    import mlflow.sklearn\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "    import os\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"  Step 4: Train Model\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    os.environ['MLFLOW_TRACKING_URI'] = mlflow_tracking_uri\n",
    "    \n",
    "    X_train_df = pd.read_csv(X_train.path)\n",
    "    X_test_df = pd.read_csv(X_test.path)\n",
    "    y_train_df = pd.read_csv(y_train.path)\n",
    "    y_test_df = pd.read_csv(y_test.path)\n",
    "    \n",
    "    mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        run_id = run.info.run_id\n",
    "        \n",
    "        params = {\"n_estimators\": n_estimators, \"max_depth\": max_depth, \"random_state\": 42}\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        model = RandomForestRegressor(**params)\n",
    "        model.fit(X_train_df, y_train_df.values.ravel())\n",
    "        \n",
    "        y_pred = model.predict(X_test_df)\n",
    "        \n",
    "        r2 = r2_score(y_test_df, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_df, y_pred))\n",
    "        mae = mean_absolute_error(y_test_df, y_pred)\n",
    "        \n",
    "        mlflow.log_metrics({\"r2\": r2, \"rmse\": rmse, \"mae\": mae})\n",
    "        mlflow.sklearn.log_model(model, \"model\", registered_model_name=f\"{experiment_name}-model\")\n",
    "        \n",
    "        print(f\"  R2: {r2:.4f}, RMSE: {rmse:.4f}\")\n",
    "        print(f\"  âœ… Run ID: {run_id}\")\n",
    "    \n",
    "    return run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 ëª¨ë¸ í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\"mlflow==2.9.2\"]\n",
    ")\n",
    "def evaluate_model(\n",
    "    run_id: str,\n",
    "    mlflow_tracking_uri: str,\n",
    "    r2_threshold: float = 0.75\n",
    ") -> str:\n",
    "    \"\"\"ëª¨ë¸ í‰ê°€ ë° ë°°í¬ ê²°ì •\"\"\"\n",
    "    import mlflow\n",
    "    import os\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"  Step 5: Evaluate Model\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    os.environ['MLFLOW_TRACKING_URI'] = mlflow_tracking_uri\n",
    "    mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "    \n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    run = client.get_run(run_id)\n",
    "    \n",
    "    r2 = float(run.data.metrics.get(\"r2\", 0))\n",
    "    \n",
    "    print(f\"  R2: {r2:.4f}, Threshold: {r2_threshold}\")\n",
    "    \n",
    "    if r2 >= r2_threshold:\n",
    "        decision = \"deploy\"\n",
    "        print(f\"  âœ… Decision: DEPLOY\")\n",
    "    else:\n",
    "        decision = \"skip\"\n",
    "        print(f\"  âš ï¸ Decision: SKIP\")\n",
    "    \n",
    "    return decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 ëª¨ë¸ ë°°í¬ / ì•Œë¦¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\"kubernetes==28.1.0\"]\n",
    ")\n",
    "def deploy_model(run_id: str, model_name: str, namespace: str):\n",
    "    \"\"\"KServe ë°°í¬\"\"\"\n",
    "    from kubernetes import client, config\n",
    "    import time\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"  Step 6: Deploy Model\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"  Model: {model_name}\")\n",
    "    print(f\"  Namespace: {namespace}\")\n",
    "    print(f\"  Run ID: {run_id}\")\n",
    "    print(f\"  âœ… Deployment initiated\")\n",
    "\n",
    "\n",
    "@component(base_image=\"python:3.9-slim\")\n",
    "def send_alert(run_id: str, message: str = \"Model did not meet threshold\"):\n",
    "    \"\"\"ì•Œë¦¼ ì „ì†¡\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"  Alert\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"  âš ï¸ {message}\")\n",
    "    print(f\"  Run ID: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. íŒŒì´í”„ë¼ì¸ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"E2E ML Pipeline\",\n",
    "    description=\"End-to-End Machine Learning Pipeline\"\n",
    ")\n",
    "def e2e_ml_pipeline(\n",
    "    data_source: str = \"sklearn\",\n",
    "    experiment_name: str = \"e2e-pipeline\",\n",
    "    model_name: str = \"california-model\",\n",
    "    namespace: str = \"kubeflow-user01\",\n",
    "    mlflow_tracking_uri: str = \"http://mlflow-server-service.mlflow-system.svc.cluster.local:5000\",\n",
    "    n_estimators: int = 100,\n",
    "    max_depth: int = 10,\n",
    "    r2_threshold: float = 0.75\n",
    "):\n",
    "    # Step 1: ë°ì´í„° ë¡œë“œ\n",
    "    load_task = load_data(data_source=data_source)\n",
    "    \n",
    "    # Step 2: ì „ì²˜ë¦¬\n",
    "    preprocess_task = preprocess(input_data=load_task.outputs[\"output_data\"])\n",
    "    \n",
    "    # Step 3: í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§\n",
    "    feature_task = feature_engineering(\n",
    "        X_train_in=preprocess_task.outputs[\"X_train_out\"],\n",
    "        X_test_in=preprocess_task.outputs[\"X_test_out\"]\n",
    "    )\n",
    "    \n",
    "    # Step 4: ëª¨ë¸ í•™ìŠµ\n",
    "    train_task = train_model(\n",
    "        X_train=feature_task.outputs[\"X_train_out\"],\n",
    "        X_test=feature_task.outputs[\"X_test_out\"],\n",
    "        y_train=preprocess_task.outputs[\"y_train_out\"],\n",
    "        y_test=preprocess_task.outputs[\"y_test_out\"],\n",
    "        mlflow_tracking_uri=mlflow_tracking_uri,\n",
    "        experiment_name=experiment_name,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth\n",
    "    )\n",
    "    \n",
    "    # Step 5: í‰ê°€\n",
    "    evaluate_task = evaluate_model(\n",
    "        run_id=train_task.output,\n",
    "        mlflow_tracking_uri=mlflow_tracking_uri,\n",
    "        r2_threshold=r2_threshold\n",
    "    )\n",
    "    \n",
    "    # Step 6: ì¡°ê±´ë¶€ ë°°í¬\n",
    "    with dsl.If(evaluate_task.output == \"deploy\"):\n",
    "        deploy_model(\n",
    "            run_id=train_task.output,\n",
    "            model_name=model_name,\n",
    "            namespace=namespace\n",
    "        )\n",
    "    \n",
    "    with dsl.If(evaluate_task.output == \"skip\"):\n",
    "        send_alert(run_id=train_task.output)\n",
    "\n",
    "print(\"âœ… íŒŒì´í”„ë¼ì¸ ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. íŒŒì´í”„ë¼ì¸ ì»´íŒŒì¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_file = \"e2e_pipeline.yaml\"\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=e2e_ml_pipeline,\n",
    "    package_path=pipeline_file\n",
    ")\n",
    "\n",
    "print(f\"âœ… Pipeline compiled: {pipeline_file}\")\n",
    "print(f\"\\në‹¤ìŒ ë‹¨ê³„:\")\n",
    "print(f\"  1. Kubeflow UI â†’ Pipelines â†’ Upload pipeline\")\n",
    "print(f\"  2. {pipeline_file} íŒŒì¼ ì„ íƒ\")\n",
    "print(f\"  3. Create Run â†’ Parameters ì„¤ì • â†’ Start\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ì„ íƒ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFP Clientë¡œ ì§ì ‘ ì‹¤í–‰ (í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ì—ì„œë§Œ ë™ì‘)\n",
    "try:\n",
    "    client = kfp.Client()\n",
    "    print(f\"âœ… KFP Client connected\")\n",
    "    print(f\"   Host: {client._host}\")\n",
    "    \n",
    "    run = client.create_run_from_pipeline_func(\n",
    "        e2e_ml_pipeline,\n",
    "        arguments={\n",
    "            'data_source': 'sklearn',\n",
    "            'experiment_name': f'e2e-pipeline-{USER_NUM}',\n",
    "            'model_name': f'california-model-{USER_NUM}',\n",
    "            'namespace': USER_NAMESPACE,\n",
    "            'n_estimators': 100,\n",
    "            'max_depth': 10,\n",
    "            'r2_threshold': 0.75\n",
    "        },\n",
    "        experiment_name=f'e2e-experiment-{USER_NUM}',\n",
    "        run_name=f'e2e-run-{USER_NUM}-001'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nâœ… Pipeline submitted!\")\n",
    "    print(f\"   Run ID: {run.run_id}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Could not connect to KFP: {e}\")\n",
    "    print(f\"\\nğŸ’¡ Upload YAML manually via Kubeflow UI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Part 1 ì™„ë£Œ!\n",
    "\n",
    "### í•™ìŠµí•œ ë‚´ìš©\n",
    "- Kubeflow Pipeline ì»´í¬ë„ŒíŠ¸ ì •ì˜\n",
    "- MLflow ì—°ë™\n",
    "- ì¡°ê±´ë¶€ ë¶„ê¸° (`dsl.If`)\n",
    "- íŒŒì´í”„ë¼ì¸ ì»´íŒŒì¼ ë° ì‹¤í–‰\n",
    "\n",
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "- Part 2: ì¡°ë³„ í”„ë¡œì íŠ¸ ì‹¤ìŠµ\n",
    "- Part 3: ë°œí‘œ ë° í”¼ë“œë°±"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
