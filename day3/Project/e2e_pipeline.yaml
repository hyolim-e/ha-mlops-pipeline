# PIPELINE DEFINITION
# Name: e2e-ml-pipeline
# Description: End-to-End Machine Learning Pipeline with MLflow and KServe
# Inputs:
#    data_source: str [Default: 'sklearn']
#    experiment_name: str [Default: 'e2e-pipeline']
#    max_depth: int [Default: 10.0]
#    mlflow_tracking_uri: str [Default: 'http://mlflow-server-service.mlflow-system.svc.cluster.local:5000']
#    model_name: str [Default: 'california-model']
#    n_estimators: int [Default: 100.0]
#    namespace: str [Default: 'kubeflow-user01']
#    r2_threshold: float [Default: 0.75]
components:
  comp-condition-1:
    dag:
      tasks:
        deploy-model:
          cachingOptions:
            enableCache: true
          componentRef:
            name: comp-deploy-model
          inputs:
            parameters:
              mlflow_tracking_uri:
                componentInputParameter: pipelinechannel--mlflow_tracking_uri
              model_name:
                componentInputParameter: pipelinechannel--model_name
              namespace:
                componentInputParameter: pipelinechannel--namespace
              run_id:
                componentInputParameter: pipelinechannel--train-model-Output
          taskInfo:
            name: deploy-model
    inputDefinitions:
      parameters:
        pipelinechannel--evaluate-model-Output:
          parameterType: STRING
        pipelinechannel--mlflow_tracking_uri:
          parameterType: STRING
        pipelinechannel--model_name:
          parameterType: STRING
        pipelinechannel--namespace:
          parameterType: STRING
        pipelinechannel--train-model-Output:
          parameterType: STRING
  comp-condition-2:
    dag:
      tasks:
        send-alert:
          cachingOptions:
            enableCache: true
          componentRef:
            name: comp-send-alert
          inputs:
            parameters:
              message:
                runtimeValue:
                  constant: Model R2 score below threshold ({{$.inputs.parameters['pipelinechannel--r2_threshold']}})
              pipelinechannel--r2_threshold:
                componentInputParameter: pipelinechannel--r2_threshold
              run_id:
                componentInputParameter: pipelinechannel--train-model-Output
          taskInfo:
            name: send-alert
    inputDefinitions:
      parameters:
        pipelinechannel--evaluate-model-Output:
          parameterType: STRING
        pipelinechannel--r2_threshold:
          parameterType: NUMBER_DOUBLE
        pipelinechannel--train-model-Output:
          parameterType: STRING
  comp-deploy-model:
    executorLabel: exec-deploy-model
    inputDefinitions:
      parameters:
        mlflow_tracking_uri:
          description: "MLflow \uC11C\uBC84 URI"
          parameterType: STRING
        model_name:
          description: "\uBAA8\uB378 \uC774\uB984"
          parameterType: STRING
        namespace:
          description: "Kubernetes \uB124\uC784\uC2A4\uD398\uC774\uC2A4"
          parameterType: STRING
        run_id:
          description: MLflow Run ID
          parameterType: STRING
  comp-evaluate-model:
    executorLabel: exec-evaluate-model
    inputDefinitions:
      parameters:
        mlflow_tracking_uri:
          description: "MLflow \uC11C\uBC84 URI"
          parameterType: STRING
        r2_threshold:
          defaultValue: 0.75
          description: "R2 \uC784\uACC4\uAC12"
          isOptional: true
          parameterType: NUMBER_DOUBLE
        run_id:
          description: MLflow Run ID
          parameterType: STRING
    outputDefinitions:
      parameters:
        Output:
          parameterType: STRING
  comp-feature-engineering:
    executorLabel: exec-feature-engineering
    inputDefinitions:
      artifacts:
        X_test_in:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        X_train_in:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        X_test_out:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        X_train_out:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        Output:
          parameterType: STRUCT
  comp-load-data:
    executorLabel: exec-load-data
    inputDefinitions:
      parameters:
        data_source:
          description: "\uB370\uC774\uD130 \uC18C\uC2A4 (\"sklearn\" \uB610\uB294\
            \ S3 \uACBD\uB85C)"
          parameterType: STRING
    outputDefinitions:
      artifacts:
        output_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-preprocess:
    executorLabel: exec-preprocess
    inputDefinitions:
      artifacts:
        input_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
          description: "\uC785\uB825 \uB370\uC774\uD130\uC14B"
      parameters:
        test_size:
          defaultValue: 0.2
          description: "\uD14C\uC2A4\uD2B8 \uC138\uD2B8 \uBE44\uC728"
          isOptional: true
          parameterType: NUMBER_DOUBLE
    outputDefinitions:
      artifacts:
        X_test_out:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        X_train_out:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        y_test_out:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        y_train_out:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        Output:
          parameterType: STRUCT
  comp-send-alert:
    executorLabel: exec-send-alert
    inputDefinitions:
      parameters:
        message:
          defaultValue: Model did not meet performance threshold
          description: "\uC54C\uB9BC \uBA54\uC2DC\uC9C0"
          isOptional: true
          parameterType: STRING
        run_id:
          description: MLflow Run ID
          parameterType: STRING
  comp-train-model:
    executorLabel: exec-train-model
    inputDefinitions:
      artifacts:
        X_test:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        X_train:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        y_test:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        y_train:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        experiment_name:
          description: "\uC2E4\uD5D8 \uC774\uB984"
          parameterType: STRING
        max_depth:
          defaultValue: 10.0
          description: "\uCD5C\uB300 \uAE4A\uC774"
          isOptional: true
          parameterType: NUMBER_INTEGER
        mlflow_tracking_uri:
          description: "MLflow \uC11C\uBC84 URI"
          parameterType: STRING
        n_estimators:
          defaultValue: 100.0
          description: "\uD2B8\uB9AC \uAC1C\uC218"
          isOptional: true
          parameterType: NUMBER_INTEGER
    outputDefinitions:
      parameters:
        Output:
          parameterType: STRING
deploymentSpec:
  executors:
    exec-deploy-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - deploy_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kubernetes==28.1.0'\
          \ 'mlflow==2.9.2'  &&  python3 -m pip install --quiet --no-warn-script-location\
          \ 'kfp==2.15.2' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"\
          3.9\"' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef deploy_model(\n    run_id: str,\n    model_name: str,\n    namespace:\
          \ str,\n    mlflow_tracking_uri: str\n):\n    \"\"\"\n    KServe InferenceService\uB85C\
          \ \uBAA8\uB378 \uBC30\uD3EC\n\n    Args:\n        run_id: MLflow Run ID\n\
          \        model_name: \uBAA8\uB378 \uC774\uB984\n        namespace: Kubernetes\
          \ \uB124\uC784\uC2A4\uD398\uC774\uC2A4\n        mlflow_tracking_uri: MLflow\
          \ \uC11C\uBC84 URI\n    \"\"\"\n    from kubernetes import client, config\n\
          \    from kubernetes.client.rest import ApiException\n    import time\n\n\
          \    print(\"=\" * 60)\n    print(\"  Step 6: Deploy Model (KServe)\")\n\
          \    print(\"=\" * 60)\n\n    print(f\"\\n  Model Name: {model_name}\")\n\
          \    print(f\"  Namespace: {namespace}\")\n    print(f\"  Run ID: {run_id}\"\
          )\n\n    try:\n        config.load_incluster_config()\n        print(\"\\\
          n  Using in-cluster config\")\n    except:\n        config.load_kube_config()\n\
          \        print(\"\\n  Using kubeconfig\")\n\n    api = client.CustomObjectsApi()\n\
          \n    # InferenceService \uC815\uC758\n    model_uri = f\"mlflow-artifacts:/{run_id}/model\"\
          \n\n    isvc = {\n        \"apiVersion\": \"serving.kserve.io/v1beta1\"\
          ,\n        \"kind\": \"InferenceService\",\n        \"metadata\": {\n  \
          \          \"name\": model_name,\n            \"namespace\": namespace,\n\
          \            \"annotations\": {\n                \"sidecar.istio.io/inject\"\
          : \"false\"\n            }\n        },\n        \"spec\": {\n          \
          \  \"predictor\": {\n                \"sklearn\": {\n                  \
          \  \"storageUri\": model_uri,\n                    \"resources\": {\n  \
          \                      \"requests\": {\n                            \"cpu\"\
          : \"100m\",\n                            \"memory\": \"256Mi\"\n       \
          \                 },\n                        \"limits\": {\n          \
          \                  \"cpu\": \"500m\",\n                            \"memory\"\
          : \"512Mi\"\n                        }\n                    }\n        \
          \        }\n            }\n        }\n    }\n\n    # \uAE30\uC874 InferenceService\
          \ \uC0AD\uC81C (\uC788\uC73C\uBA74)\n    try:\n        api.delete_namespaced_custom_object(\n\
          \            group=\"serving.kserve.io\",\n            version=\"v1beta1\"\
          ,\n            namespace=namespace,\n            plural=\"inferenceservices\"\
          ,\n            name=model_name\n        )\n        print(f\"\\n  Deleted\
          \ existing InferenceService: {model_name}\")\n        time.sleep(5)\n  \
          \  except ApiException as e:\n        if e.status != 404:\n            raise\n\
          \n    # \uC0C8 InferenceService \uC0DD\uC131\n    print(f\"\\n  Creating\
          \ InferenceService...\")\n    try:\n        api.create_namespaced_custom_object(\n\
          \            group=\"serving.kserve.io\",\n            version=\"v1beta1\"\
          ,\n            namespace=namespace,\n            plural=\"inferenceservices\"\
          ,\n            body=isvc\n        )\n        print(f\"  \u2705 InferenceService\
          \ created: {model_name}\")\n    except ApiException as e:\n        print(f\"\
          \  \u274C Failed to create InferenceService: {e.reason}\")\n        raise\n\
          \n    # \uC0C1\uD0DC \uD655\uC778\n    print(f\"\\n  Waiting for deployment\
          \ (max 60s)...\")\n    for i in range(6):\n        time.sleep(10)\n    \
          \    try:\n            status = api.get_namespaced_custom_object(\n    \
          \            group=\"serving.kserve.io\",\n                version=\"v1beta1\"\
          ,\n                namespace=namespace,\n                plural=\"inferenceservices\"\
          ,\n                name=model_name\n            )\n            conditions\
          \ = status.get(\"status\", {}).get(\"conditions\", [])\n            ready\
          \ = next(\n                (c for c in conditions if c.get(\"type\") ==\
          \ \"Ready\"),\n                None\n            )\n            if ready\
          \ and ready.get(\"status\") == \"True\":\n                print(f\"  \u2705\
          \ InferenceService READY!\")\n                break\n            print(f\"\
          \  \u23F3 Status: {ready.get('status') if ready else 'Unknown'} ({(i+1)*10}s)\"\
          )\n        except Exception as e:\n            print(f\"  \u26A0\uFE0F Status\
          \ check failed: {e}\")\n\n    print(f\"\\n  Endpoint:\")\n    print(f\"\
          \    http://{model_name}.{namespace}.svc.cluster.local/v1/models/{model_name}:predict\"\
          )\n    print(f\"\\n  \u2705 Deployment completed!\")\n\n"
        image: python:3.9-slim
    exec-evaluate-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - evaluate_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'mlflow==2.9.2'\
          \  &&  python3 -m pip install --quiet --no-warn-script-location 'kfp==2.15.2'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef evaluate_model(\n    run_id: str,\n    mlflow_tracking_uri: str,\n\
          \    r2_threshold: float = 0.75\n) -> str:\n    \"\"\"\n    \uBAA8\uB378\
          \ \uC131\uB2A5 \uD3C9\uAC00 \uBC0F \uBC30\uD3EC \uACB0\uC815\n\n    Args:\n\
          \        run_id: MLflow Run ID\n        mlflow_tracking_uri: MLflow \uC11C\
          \uBC84 URI\n        r2_threshold: R2 \uC784\uACC4\uAC12\n\n    Returns:\n\
          \        \"deploy\" \uB610\uB294 \"skip\"\n    \"\"\"\n    import mlflow\n\
          \    import os\n\n    print(\"=\" * 60)\n    print(\"  Step 5: Evaluate\
          \ Model\")\n    print(\"=\" * 60)\n\n    os.environ['MLFLOW_TRACKING_URI']\
          \ = mlflow_tracking_uri\n    mlflow.set_tracking_uri(mlflow_tracking_uri)\n\
          \n    client = mlflow.tracking.MlflowClient()\n    run = client.get_run(run_id)\n\
          \n    # \uBA54\uD2B8\uB9AD \uAC00\uC838\uC624\uAE30\n    r2 = float(run.data.metrics.get(\"\
          r2\", 0))\n    rmse = float(run.data.metrics.get(\"rmse\", 0))\n    mae\
          \ = float(run.data.metrics.get(\"mae\", 0))\n\n    print(f\"\\n  Run ID:\
          \ {run_id}\")\n    print(f\"\\n  Model Metrics:\")\n    print(f\"    - R2\
          \ Score: {r2:.4f}\")\n    print(f\"    - RMSE: {rmse:.4f}\")\n    print(f\"\
          \    - MAE: {mae:.4f}\")\n    print(f\"\\n  Deployment Threshold:\")\n \
          \   print(f\"    - R2 >= {r2_threshold}\")\n\n    # \uBC30\uD3EC \uACB0\uC815\
          \n    if r2 >= r2_threshold:\n        decision = \"deploy\"\n        print(f\"\
          \\n  \u2705 Decision: DEPLOY\")\n        print(f\"     R2 ({r2:.4f}) >=\
          \ Threshold ({r2_threshold})\")\n    else:\n        decision = \"skip\"\n\
          \        print(f\"\\n  \u26A0\uFE0F Decision: SKIP\")\n        print(f\"\
          \     R2 ({r2:.4f}) < Threshold ({r2_threshold})\")\n\n    # MLflow\uC5D0\
          \ \uACB0\uC815 \uAE30\uB85D\n    with mlflow.start_run(run_id=run_id):\n\
          \        mlflow.set_tag(\"deployment_decision\", decision)\n        mlflow.log_metric(\"\
          r2_threshold\", r2_threshold)\n\n    return decision\n\n"
        image: python:3.9-slim
    exec-feature-engineering:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - feature_engineering
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'pandas==2.0.3'\
          \ 'numpy==1.24.3'  &&  python3 -m pip install --quiet --no-warn-script-location\
          \ 'kfp==2.15.2' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"\
          3.9\"' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef feature_engineering(\n    X_train_in: Input[Dataset],\n    X_test_in:\
          \ Input[Dataset],\n    X_train_out: Output[Dataset],\n    X_test_out: Output[Dataset]\n\
          ) -> dict:\n    \"\"\"\n    \uD53C\uCC98 \uC5D4\uC9C0\uB2C8\uC5B4\uB9C1\
          : \uD30C\uC0DD \uBCC0\uC218 \uC0DD\uC131\n\n    \uC0DD\uC131\uB418\uB294\
          \ \uD53C\uCC98:\n    - rooms_per_household: \uAC00\uAD6C\uB2F9 \uBC29 \uC218\
          \n    - bedrooms_ratio: \uBC29 \uB300\uBE44 \uCE68\uC2E4 \uBE44\uC728\n\
          \    - population_per_household: \uAC00\uAD6C\uB2F9 \uC778\uAD6C\n    \"\
          \"\"\n    import pandas as pd\n    import numpy as np\n\n    print(\"=\"\
          \ * 60)\n    print(\"  Step 3: Feature Engineering\")\n    print(\"=\" *\
          \ 60)\n\n    X_train = pd.read_csv(X_train_in.path)\n    X_test = pd.read_csv(X_test_in.path)\n\
          \n    original_features = list(X_train.columns)\n    print(f\"\\n  Original\
          \ features: {original_features}\")\n\n    def add_features(df):\n      \
          \  \"\"\"\uD30C\uC0DD \uBCC0\uC218 \uCD94\uAC00\"\"\"\n        df = df.copy()\n\
          \n        # 1. \uAC00\uAD6C\uB2F9 \uBC29 \uC218 (\uC774\uBBF8 \uC2A4\uCF00\
          \uC77C\uB9C1\uB428 - \uC5ED\uC2A4\uCF00\uC77C\uB9C1 \uC5C6\uC774 \uBE44\uC728\
          \ \uACC4\uC0B0)\n        if 'AveRooms' in df.columns and 'AveOccup' in df.columns:\n\
          \            df['rooms_per_household'] = df['AveRooms'] / (df['AveOccup']\
          \ + 1e-6)\n\n        # 2. \uBC29 \uB300\uBE44 \uCE68\uC2E4 \uBE44\uC728\n\
          \        if 'AveBedrms' in df.columns and 'AveRooms' in df.columns:\n  \
          \          df['bedrooms_ratio'] = df['AveBedrms'] / (df['AveRooms'] + 1e-6)\n\
          \n        # 3. \uAC00\uAD6C\uB2F9 \uC778\uAD6C\n        if 'Population'\
          \ in df.columns and 'AveOccup' in df.columns:\n            df['population_per_household']\
          \ = df['Population'] / (df['AveOccup'] + 1e-6)\n\n        return df\n\n\
          \    X_train_fe = add_features(X_train)\n    X_test_fe = add_features(X_test)\n\
          \n    new_features = [f for f in X_train_fe.columns if f not in original_features]\n\
          \    print(f\"  New features: {new_features}\")\n    print(f\"  Total features:\
          \ {len(X_train_fe.columns)}\")\n\n    X_train_fe.to_csv(X_train_out.path,\
          \ index=False)\n    X_test_fe.to_csv(X_test_out.path, index=False)\n\n \
          \   print(f\"\\n  \u2705 Feature engineering completed\")\n\n    return\
          \ {\n        \"original_features\": len(original_features),\n        \"\
          new_features\": len(new_features),\n        \"total_features\": len(X_train_fe.columns)\n\
          \    }\n\n"
        image: python:3.9-slim
    exec-load-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - load_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'pandas==2.0.3'\
          \ 'scikit-learn==1.3.2'  &&  python3 -m pip install --quiet --no-warn-script-location\
          \ 'kfp==2.15.2' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"\
          3.9\"' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef load_data(\n    data_source: str,\n    output_data: Output[Dataset]\n\
          ):\n    \"\"\"\n    California Housing \uB370\uC774\uD130\uC14B \uB85C\uB4DC\
          \n\n    Args:\n        data_source: \uB370\uC774\uD130 \uC18C\uC2A4 (\"\
          sklearn\" \uB610\uB294 S3 \uACBD\uB85C)\n        output_data: \uCD9C\uB825\
          \ \uB370\uC774\uD130\uC14B\n    \"\"\"\n    import pandas as pd\n    from\
          \ sklearn.datasets import fetch_california_housing\n\n    print(\"=\" *\
          \ 60)\n    print(\"  Step 1: Load Data\")\n    print(\"=\" * 60)\n\n   \
          \ if data_source == \"sklearn\":\n        print(\"\\n  Loading from sklearn...\"\
          )\n        housing = fetch_california_housing(as_frame=True)\n        df\
          \ = housing.frame\n    else:\n        print(f\"\\n  Loading from: {data_source}\"\
          )\n        df = pd.read_csv(data_source)\n\n    print(f\"\\n  Data shape:\
          \ {df.shape}\")\n    print(f\"  Columns: {list(df.columns)}\")\n    print(f\"\
          \\n  First 5 rows:\")\n    print(df.head())\n\n    df.to_csv(output_data.path,\
          \ index=False)\n    print(f\"\\n  \u2705 Data saved to: {output_data.path}\"\
          )\n\n"
        image: python:3.9-slim
    exec-preprocess:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - preprocess
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'pandas==2.0.3'\
          \ 'scikit-learn==1.3.2' 'numpy==1.24.3'  &&  python3 -m pip install --quiet\
          \ --no-warn-script-location 'kfp==2.15.2' '--no-deps' 'typing-extensions>=3.7.4,<5;\
          \ python_version<\"3.9\"' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef preprocess(\n    input_data: Input[Dataset],\n    X_train_out:\
          \ Output[Dataset],\n    X_test_out: Output[Dataset],\n    y_train_out: Output[Dataset],\n\
          \    y_test_out: Output[Dataset],\n    test_size: float = 0.2\n) -> dict:\n\
          \    \"\"\"\n    \uB370\uC774\uD130 \uC804\uCC98\uB9AC: Train/Test \uBD84\
          \uD560 \uBC0F \uC815\uADDC\uD654\n\n    Args:\n        input_data: \uC785\
          \uB825 \uB370\uC774\uD130\uC14B\n        test_size: \uD14C\uC2A4\uD2B8 \uC138\
          \uD2B8 \uBE44\uC728\n\n    Returns:\n        \uC804\uCC98\uB9AC \uBA54\uD0C0\
          \uB370\uC774\uD130\n    \"\"\"\n    import pandas as pd\n    import numpy\
          \ as np\n    from sklearn.model_selection import train_test_split\n    from\
          \ sklearn.preprocessing import StandardScaler\n\n    print(\"=\" * 60)\n\
          \    print(\"  Step 2: Preprocess\")\n    print(\"=\" * 60)\n\n    df =\
          \ pd.read_csv(input_data.path)\n    print(f\"\\n  Loaded {len(df)} rows\"\
          )\n\n    # \uD53C\uCC98\uC640 \uD0C0\uAC9F \uBD84\uB9AC\n    target_col\
          \ = \"MedHouseVal\"\n    X = df.drop(columns=[target_col])\n    y = df[target_col]\n\
          \n    print(f\"  Features: {list(X.columns)}\")\n    print(f\"  Target:\
          \ {target_col}\")\n\n    # Train/Test \uBD84\uD560\n    X_train, X_test,\
          \ y_train, y_test = train_test_split(\n        X, y, test_size=test_size,\
          \ random_state=42\n    )\n\n    print(f\"\\n  Train size: {len(X_train)}\"\
          )\n    print(f\"  Test size: {len(X_test)}\")\n\n    # \uC815\uADDC\uD654\
          \n    scaler = StandardScaler()\n    X_train_scaled = pd.DataFrame(\n  \
          \      scaler.fit_transform(X_train),\n        columns=X_train.columns\n\
          \    )\n    X_test_scaled = pd.DataFrame(\n        scaler.transform(X_test),\n\
          \        columns=X_test.columns\n    )\n\n    # \uC800\uC7A5\n    X_train_scaled.to_csv(X_train_out.path,\
          \ index=False)\n    X_test_scaled.to_csv(X_test_out.path, index=False)\n\
          \    y_train.to_csv(y_train_out.path, index=False)\n    y_test.to_csv(y_test_out.path,\
          \ index=False)\n\n    print(f\"\\n  \u2705 Preprocessing completed\")\n\n\
          \    return {\n        \"n_train\": len(X_train),\n        \"n_test\": len(X_test),\n\
          \        \"n_features\": X_train.shape[1]\n    }\n\n"
        image: python:3.9-slim
    exec-send-alert:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - send_alert
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.15.2'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef send_alert(\n    run_id: str,\n    message: str = \"Model did\
          \ not meet performance threshold\"\n):\n    \"\"\"\n    \uC131\uB2A5 \uBBF8\
          \uB2EC \uC54C\uB9BC \uC804\uC1A1\n\n    Args:\n        run_id: MLflow Run\
          \ ID\n        message: \uC54C\uB9BC \uBA54\uC2DC\uC9C0\n    \"\"\"\n   \
          \ print(\"=\" * 60)\n    print(\"  Step 6 (Alt): Send Alert\")\n    print(\"\
          =\" * 60)\n\n    print(f\"\\n  \u26A0\uFE0F ALERT: {message}\")\n    print(f\"\
          \  Run ID: {run_id}\")\n    print(f\"\\n  Actions required:\")\n    print(f\"\
          \    1. Review model performance in MLflow\")\n    print(f\"    2. Check\
          \ data quality\")\n    print(f\"    3. Tune hyperparameters\")\n    print(f\"\
          \    4. Re-run pipeline\")\n\n"
        image: python:3.9-slim
    exec-train-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - train_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'pandas==2.0.3'\
          \ 'scikit-learn==1.3.2' 'mlflow==2.9.2' 'boto3==1.34.0'  &&  python3 -m\
          \ pip install --quiet --no-warn-script-location 'kfp==2.15.2' '--no-deps'\
          \ 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\
          \n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef train_model(\n    X_train: Input[Dataset],\n    X_test: Input[Dataset],\n\
          \    y_train: Input[Dataset],\n    y_test: Input[Dataset],\n    mlflow_tracking_uri:\
          \ str,\n    experiment_name: str,\n    n_estimators: int = 100,\n    max_depth:\
          \ int = 10\n) -> str:\n    \"\"\"\n    \uBAA8\uB378 \uD559\uC2B5 \uBC0F\
          \ MLflow \uAE30\uB85D\n\n    Args:\n        mlflow_tracking_uri: MLflow\
          \ \uC11C\uBC84 URI\n        experiment_name: \uC2E4\uD5D8 \uC774\uB984\n\
          \        n_estimators: \uD2B8\uB9AC \uAC1C\uC218\n        max_depth: \uCD5C\
          \uB300 \uAE4A\uC774\n\n    Returns:\n        MLflow Run ID\n    \"\"\"\n\
          \    import pandas as pd\n    import numpy as np\n    import mlflow\n  \
          \  import mlflow.sklearn\n    from sklearn.ensemble import RandomForestRegressor\n\
          \    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n\
          \    import os\n\n    print(\"=\" * 60)\n    print(\"  Step 4: Train Model\"\
          )\n    print(\"=\" * 60)\n\n    # \uB370\uC774\uD130 \uB85C\uB4DC\n    X_train_df\
          \ = pd.read_csv(X_train.path)\n    X_test_df = pd.read_csv(X_test.path)\n\
          \    y_train_df = pd.read_csv(y_train.path)\n    y_test_df = pd.read_csv(y_test.path)\n\
          \n    print(f\"\\n  Training data: {X_train_df.shape}\")\n    print(f\"\
          \  Test data: {X_test_df.shape}\")\n\n    # MLflow \uC124\uC815\n    os.environ['MLFLOW_TRACKING_URI']\
          \ = mlflow_tracking_uri\n    mlflow.set_tracking_uri(mlflow_tracking_uri)\n\
          \    mlflow.set_experiment(experiment_name)\n\n    print(f\"\\n  MLflow\
          \ Tracking URI: {mlflow_tracking_uri}\")\n    print(f\"  Experiment: {experiment_name}\"\
          )\n\n    # \uD559\uC2B5\n    with mlflow.start_run() as run:\n        run_id\
          \ = run.info.run_id\n        print(f\"\\n  Run ID: {run_id}\")\n\n     \
          \   # \uD30C\uB77C\uBBF8\uD130 \uB85C\uAE45\n        params = {\n      \
          \      \"n_estimators\": n_estimators,\n            \"max_depth\": max_depth,\n\
          \            \"random_state\": 42,\n            \"n_jobs\": -1\n       \
          \ }\n        mlflow.log_params(params)\n\n        # \uBAA8\uB378 \uD559\uC2B5\
          \n        print(\"\\n  Training RandomForest model...\")\n        model\
          \ = RandomForestRegressor(**params)\n        model.fit(X_train_df, y_train_df.values.ravel())\n\
          \n        # \uC608\uCE21 \uBC0F \uD3C9\uAC00\n        y_pred = model.predict(X_test_df)\n\
          \n        mse = mean_squared_error(y_test_df, y_pred)\n        rmse = np.sqrt(mse)\n\
          \        mae = mean_absolute_error(y_test_df, y_pred)\n        r2 = r2_score(y_test_df,\
          \ y_pred)\n\n        # \uBA54\uD2B8\uB9AD \uB85C\uAE45\n        metrics\
          \ = {\n            \"mse\": mse,\n            \"rmse\": rmse,\n        \
          \    \"mae\": mae,\n            \"r2\": r2\n        }\n        mlflow.log_metrics(metrics)\n\
          \n        print(f\"\\n  Model Performance:\")\n        print(f\"    - R2\
          \ Score: {r2:.4f}\")\n        print(f\"    - RMSE: {rmse:.4f}\")\n     \
          \   print(f\"    - MAE: {mae:.4f}\")\n\n        # \uD53C\uCC98 \uC911\uC694\
          \uB3C4 \uB85C\uAE45\n        feature_importance = dict(zip(\n          \
          \  X_train_df.columns,\n            model.feature_importances_\n       \
          \ ))\n        mlflow.log_dict(feature_importance, \"feature_importance.json\"\
          )\n\n        # \uBAA8\uB378 \uC800\uC7A5\n        mlflow.sklearn.log_model(\n\
          \            model,\n            \"model\",\n            registered_model_name=f\"\
          {experiment_name}-model\"\n        )\n\n        # \uD0DC\uADF8 \uCD94\uAC00\
          \n        mlflow.set_tags({\n            \"pipeline\": \"e2e\",\n      \
          \      \"stage\": \"training\",\n            \"n_features\": X_train_df.shape[1]\n\
          \        })\n\n    print(f\"\\n  \u2705 Training completed! Run ID: {run_id}\"\
          )\n\n    return run_id\n\n"
        image: python:3.9-slim
pipelineInfo:
  description: End-to-End Machine Learning Pipeline with MLflow and KServe
  name: e2e-ml-pipeline
root:
  dag:
    tasks:
      condition-1:
        componentRef:
          name: comp-condition-1
        dependentTasks:
        - evaluate-model
        - train-model
        inputs:
          parameters:
            pipelinechannel--evaluate-model-Output:
              taskOutputParameter:
                outputParameterKey: Output
                producerTask: evaluate-model
            pipelinechannel--mlflow_tracking_uri:
              componentInputParameter: mlflow_tracking_uri
            pipelinechannel--model_name:
              componentInputParameter: model_name
            pipelinechannel--namespace:
              componentInputParameter: namespace
            pipelinechannel--train-model-Output:
              taskOutputParameter:
                outputParameterKey: Output
                producerTask: train-model
        taskInfo:
          name: condition-1
        triggerPolicy:
          condition: inputs.parameter_values['pipelinechannel--evaluate-model-Output']
            == 'deploy'
      condition-2:
        componentRef:
          name: comp-condition-2
        dependentTasks:
        - evaluate-model
        - train-model
        inputs:
          parameters:
            pipelinechannel--evaluate-model-Output:
              taskOutputParameter:
                outputParameterKey: Output
                producerTask: evaluate-model
            pipelinechannel--r2_threshold:
              componentInputParameter: r2_threshold
            pipelinechannel--train-model-Output:
              taskOutputParameter:
                outputParameterKey: Output
                producerTask: train-model
        taskInfo:
          name: condition-2
        triggerPolicy:
          condition: inputs.parameter_values['pipelinechannel--evaluate-model-Output']
            == 'skip'
      evaluate-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-evaluate-model
        dependentTasks:
        - train-model
        inputs:
          parameters:
            mlflow_tracking_uri:
              componentInputParameter: mlflow_tracking_uri
            r2_threshold:
              componentInputParameter: r2_threshold
            run_id:
              taskOutputParameter:
                outputParameterKey: Output
                producerTask: train-model
        taskInfo:
          name: evaluate-model
      feature-engineering:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-feature-engineering
        dependentTasks:
        - preprocess
        inputs:
          artifacts:
            X_test_in:
              taskOutputArtifact:
                outputArtifactKey: X_test_out
                producerTask: preprocess
            X_train_in:
              taskOutputArtifact:
                outputArtifactKey: X_train_out
                producerTask: preprocess
        taskInfo:
          name: feature-engineering
      load-data:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-load-data
        inputs:
          parameters:
            data_source:
              componentInputParameter: data_source
        taskInfo:
          name: load-data
      preprocess:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-preprocess
        dependentTasks:
        - load-data
        inputs:
          artifacts:
            input_data:
              taskOutputArtifact:
                outputArtifactKey: output_data
                producerTask: load-data
        taskInfo:
          name: preprocess
      train-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-train-model
        dependentTasks:
        - feature-engineering
        - preprocess
        inputs:
          artifacts:
            X_test:
              taskOutputArtifact:
                outputArtifactKey: X_test_out
                producerTask: feature-engineering
            X_train:
              taskOutputArtifact:
                outputArtifactKey: X_train_out
                producerTask: feature-engineering
            y_test:
              taskOutputArtifact:
                outputArtifactKey: y_test_out
                producerTask: preprocess
            y_train:
              taskOutputArtifact:
                outputArtifactKey: y_train_out
                producerTask: preprocess
          parameters:
            experiment_name:
              componentInputParameter: experiment_name
            max_depth:
              componentInputParameter: max_depth
            mlflow_tracking_uri:
              componentInputParameter: mlflow_tracking_uri
            n_estimators:
              componentInputParameter: n_estimators
        taskInfo:
          name: train-model
  inputDefinitions:
    parameters:
      data_source:
        defaultValue: sklearn
        description: "\uB370\uC774\uD130 \uC18C\uC2A4 (\"sklearn\" \uB610\uB294 S3\
          \ \uACBD\uB85C)"
        isOptional: true
        parameterType: STRING
      experiment_name:
        defaultValue: e2e-pipeline
        description: "MLflow \uC2E4\uD5D8 \uC774\uB984"
        isOptional: true
        parameterType: STRING
      max_depth:
        defaultValue: 10.0
        description: "RandomForest \uCD5C\uB300 \uAE4A\uC774"
        isOptional: true
        parameterType: NUMBER_INTEGER
      mlflow_tracking_uri:
        defaultValue: http://mlflow-server-service.mlflow-system.svc.cluster.local:5000
        description: "MLflow \uC11C\uBC84 URI"
        isOptional: true
        parameterType: STRING
      model_name:
        defaultValue: california-model
        description: "\uBAA8\uB378/InferenceService \uC774\uB984"
        isOptional: true
        parameterType: STRING
      n_estimators:
        defaultValue: 100.0
        description: "RandomForest \uD2B8\uB9AC \uAC1C\uC218"
        isOptional: true
        parameterType: NUMBER_INTEGER
      namespace:
        defaultValue: kubeflow-user01
        description: "Kubernetes \uB124\uC784\uC2A4\uD398\uC774\uC2A4"
        isOptional: true
        parameterType: STRING
      r2_threshold:
        defaultValue: 0.75
        description: "\uBC30\uD3EC \uACB0\uC815 R2 \uC784\uACC4\uAC12"
        isOptional: true
        parameterType: NUMBER_DOUBLE
schemaVersion: 2.1.0
sdkVersion: kfp-2.15.2
